{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (49000, 6400)\n",
      "val (1000, 6400)\n",
      "test (1000, 6400)\n"
     ]
    }
   ],
   "source": [
    "# just test the password\n",
    "import cPickle as pickle\n",
    "with open(\"features.pickle\") as f:\n",
    "    [trainXC,valXC,testXC,y_train,y_val,y_test]=pickle.load(f)\n",
    "\n",
    "print \"train\",trainXC.shape\n",
    "print \"val\",valXC.shape\n",
    "print \"test\",testXC.shape\n",
    "# In[125]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 / 20000: loss 2.301803\n",
      "iteration 200 / 20000: loss 2.266133\n",
      "iteration 300 / 20000: loss 2.075131\n",
      "train_acc 0.343750, val_acc 0.294000, time 1\n",
      "iteration 400 / 20000: loss 1.931901\n",
      "iteration 500 / 20000: loss 1.717038\n",
      "iteration 600 / 20000: loss 1.690896\n",
      "iteration 700 / 20000: loss 1.655042\n",
      "train_acc 0.421875, val_acc 0.433000, time 2\n",
      "iteration 800 / 20000: loss 1.498945\n",
      "iteration 900 / 20000: loss 1.713685\n",
      "iteration 1000 / 20000: loss 1.698893\n",
      "iteration 1100 / 20000: loss 1.406769\n",
      "train_acc 0.460938, val_acc 0.525000, time 3\n",
      "iteration 1200 / 20000: loss 1.499386\n",
      "iteration 1300 / 20000: loss 1.493544\n",
      "iteration 1400 / 20000: loss 1.156674\n",
      "iteration 1500 / 20000: loss 1.313943\n",
      "train_acc 0.625000, val_acc 0.559000, time 5\n",
      "iteration 1600 / 20000: loss 1.323671\n",
      "iteration 1700 / 20000: loss 1.246637\n",
      "iteration 1800 / 20000: loss 1.078736\n",
      "iteration 1900 / 20000: loss 1.163683\n",
      "train_acc 0.601562, val_acc 0.587000, time 6\n",
      "iteration 2000 / 20000: loss 1.139835\n",
      "iteration 2100 / 20000: loss 1.299037\n",
      "iteration 2200 / 20000: loss 1.243244\n",
      "train_acc 0.656250, val_acc 0.589000, time 7\n",
      "iteration 2300 / 20000: loss 1.290659\n",
      "iteration 2400 / 20000: loss 1.246766\n",
      "iteration 2500 / 20000: loss 1.320941\n",
      "iteration 2600 / 20000: loss 1.314428\n",
      "train_acc 0.632812, val_acc 0.583000, time 9\n",
      "iteration 2700 / 20000: loss 1.187567\n",
      "iteration 2800 / 20000: loss 1.296029\n",
      "iteration 2900 / 20000: loss 1.082288\n",
      "iteration 3000 / 20000: loss 1.186433\n",
      "train_acc 0.562500, val_acc 0.600000, time 10\n",
      "iteration 3100 / 20000: loss 1.172082\n",
      "iteration 3200 / 20000: loss 1.139693\n",
      "iteration 3300 / 20000: loss 1.207931\n",
      "iteration 3400 / 20000: loss 1.134905\n",
      "train_acc 0.640625, val_acc 0.617000, time 11\n",
      "iteration 3500 / 20000: loss 1.071889\n",
      "iteration 3600 / 20000: loss 1.275131\n",
      "iteration 3700 / 20000: loss 1.097668\n",
      "iteration 3800 / 20000: loss 1.173952\n",
      "train_acc 0.609375, val_acc 0.619000, time 12\n",
      "iteration 3900 / 20000: loss 1.119036\n",
      "iteration 4000 / 20000: loss 1.131334\n",
      "iteration 4100 / 20000: loss 1.167215\n",
      "iteration 4200 / 20000: loss 1.155608\n",
      "train_acc 0.656250, val_acc 0.616000, time 14\n",
      "iteration 4300 / 20000: loss 1.130568\n",
      "iteration 4400 / 20000: loss 1.126406\n",
      "iteration 4500 / 20000: loss 1.000996\n",
      "train_acc 0.640625, val_acc 0.628000, time 15\n",
      "iteration 4600 / 20000: loss 1.158514\n",
      "iteration 4700 / 20000: loss 1.064157\n",
      "iteration 4800 / 20000: loss 0.931007\n",
      "iteration 4900 / 20000: loss 1.327285\n",
      "train_acc 0.664062, val_acc 0.627000, time 16\n",
      "iteration 5000 / 20000: loss 1.037436\n",
      "iteration 5100 / 20000: loss 1.101354\n",
      "iteration 5200 / 20000: loss 1.121930\n",
      "iteration 5300 / 20000: loss 1.169010\n",
      "train_acc 0.671875, val_acc 0.618000, time 18\n",
      "iteration 5400 / 20000: loss 1.124760\n",
      "iteration 5500 / 20000: loss 1.087625\n",
      "iteration 5600 / 20000: loss 1.076195\n",
      "iteration 5700 / 20000: loss 1.157072\n",
      "train_acc 0.664062, val_acc 0.635000, time 19\n",
      "iteration 5800 / 20000: loss 1.099319\n",
      "iteration 5900 / 20000: loss 0.966720\n",
      "iteration 6000 / 20000: loss 1.050900\n",
      "iteration 6100 / 20000: loss 1.011743\n",
      "train_acc 0.648438, val_acc 0.629000, time 21\n",
      "iteration 6200 / 20000: loss 1.031296\n",
      "iteration 6300 / 20000: loss 1.071438\n",
      "iteration 6400 / 20000: loss 1.220744\n",
      "train_acc 0.726562, val_acc 0.618000, time 23\n",
      "iteration 6500 / 20000: loss 1.232750\n",
      "iteration 6600 / 20000: loss 0.976652\n",
      "iteration 6700 / 20000: loss 0.975526\n",
      "iteration 6800 / 20000: loss 1.012550\n",
      "train_acc 0.664062, val_acc 0.636000, time 26\n",
      "iteration 6900 / 20000: loss 1.045817\n",
      "iteration 7000 / 20000: loss 1.058799\n",
      "iteration 7100 / 20000: loss 1.239590\n",
      "iteration 7200 / 20000: loss 0.943736\n",
      "train_acc 0.640625, val_acc 0.631000, time 29\n",
      "iteration 7300 / 20000: loss 1.005397\n",
      "iteration 7400 / 20000: loss 0.900447\n",
      "iteration 7500 / 20000: loss 1.061628\n",
      "iteration 7600 / 20000: loss 1.031495\n",
      "train_acc 0.718750, val_acc 0.639000, time 31\n",
      "iteration 7700 / 20000: loss 0.921122\n",
      "iteration 7800 / 20000: loss 1.030468\n",
      "iteration 7900 / 20000: loss 1.022492\n",
      "iteration 8000 / 20000: loss 1.105411\n",
      "train_acc 0.703125, val_acc 0.649000, time 34\n",
      "iteration 8100 / 20000: loss 0.997554\n",
      "iteration 8200 / 20000: loss 0.983584\n",
      "iteration 8300 / 20000: loss 1.008066\n",
      "iteration 8400 / 20000: loss 0.878010\n",
      "train_acc 0.703125, val_acc 0.651000, time 36\n",
      "iteration 8500 / 20000: loss 1.232291\n",
      "iteration 8600 / 20000: loss 0.838676\n",
      "iteration 8700 / 20000: loss 1.142964\n",
      "train_acc 0.679688, val_acc 0.635000, time 38\n",
      "iteration 8800 / 20000: loss 0.948447\n",
      "iteration 8900 / 20000: loss 1.110439\n",
      "iteration 9000 / 20000: loss 1.043731\n",
      "iteration 9100 / 20000: loss 1.110174\n",
      "train_acc 0.679688, val_acc 0.646000, time 41\n",
      "iteration 9200 / 20000: loss 1.096975\n",
      "iteration 9300 / 20000: loss 1.123846\n",
      "iteration 9400 / 20000: loss 1.040992\n",
      "iteration 9500 / 20000: loss 0.944924\n",
      "train_acc 0.601562, val_acc 0.654000, time 43\n",
      "iteration 9600 / 20000: loss 1.107178\n",
      "iteration 9700 / 20000: loss 1.260756\n",
      "iteration 9800 / 20000: loss 1.092512\n",
      "iteration 9900 / 20000: loss 0.968953\n",
      "train_acc 0.664062, val_acc 0.669000, time 45\n",
      "iteration 10000 / 20000: loss 1.133016\n",
      "iteration 10100 / 20000: loss 1.222700\n",
      "iteration 10200 / 20000: loss 1.069049\n",
      "iteration 10300 / 20000: loss 1.180612\n",
      "train_acc 0.609375, val_acc 0.644000, time 48\n",
      "iteration 10400 / 20000: loss 1.060628\n",
      "iteration 10500 / 20000: loss 1.077029\n",
      "iteration 10600 / 20000: loss 1.029770\n",
      "train_acc 0.648438, val_acc 0.641000, time 50\n",
      "iteration 10700 / 20000: loss 1.166514\n",
      "iteration 10800 / 20000: loss 0.954517\n",
      "iteration 10900 / 20000: loss 1.074591\n",
      "iteration 11000 / 20000: loss 0.948868\n",
      "train_acc 0.703125, val_acc 0.656000, time 53\n",
      "iteration 11100 / 20000: loss 1.080018\n",
      "iteration 11200 / 20000: loss 1.080617\n",
      "iteration 11300 / 20000: loss 1.186455\n",
      "iteration 11400 / 20000: loss 1.082939\n",
      "train_acc 0.671875, val_acc 0.660000, time 55\n",
      "iteration 11500 / 20000: loss 0.951830\n",
      "iteration 11600 / 20000: loss 1.047474\n",
      "iteration 11700 / 20000: loss 1.189418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-22f0a8123796>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m                         \u001b[0mnum_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                         \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate_decay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                         reg=0, verbose=True,update=\"momentum\",arg=momentum,dropout=dropout)\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Predict on the validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eli/work/mp1/neural_net.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, X_val, y_val, learning_rate, learning_rate_decay, reg, num_iters, batch_size, verbose, update, arg, dropout, activation)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m       \u001b[1;31m# Compute loss and gradients using the current minibatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m       \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropMask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropMask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m       \u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/eli/work/mp1/neural_net.pyc\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, X, y, reg, dropout, dropMask, activation)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mdelta_2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelta_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mreg\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m     \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;31m#############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from neural_net import *\n",
    "import matplotlib.pyplot as plt\n",
    "input_size = trainXC.shape[1]\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "# In[126]:\n",
    "import os.path\n",
    "if not os.path.isfile(\"feats.csv\"):\n",
    "    with open(\"feats.csv\",\"w\") as f:\n",
    "        f.write(\"hidden_size,momentum,dropout,learning_rate,learning_rate_decay\"+'\\n')\n",
    "\n",
    "hidden_size=500\n",
    "momentum=.99\n",
    "learning_rate=2e-4\n",
    "learning_rate_decay=.99\n",
    "dropout=.3\n",
    "\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes,1e-4)\n",
    "stats = net.train(trainXC, y_train, valXC, y_val,\n",
    "                        num_iters=20000, batch_size=128,\n",
    "                        learning_rate=learning_rate, learning_rate_decay=learning_rate_decay,\n",
    "                        reg=0, verbose=True,update=\"momentum\",arg=momentum,dropout=dropout)\n",
    "\n",
    "# Predict on the validation set\n",
    "val_acc = (net.predict(trainXC) == y_train).mean()\n",
    "print 'Train accuracy: ', val_acc\n",
    "val_acc = (net.predict(valXC) == y_val).mean()\n",
    "print 'Validation accuracy: ', val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 / 15000: loss 2.228800\n",
      "iteration 200 / 15000: loss 1.865953\n",
      "iteration 300 / 15000: loss 1.813429\n",
      "train_acc 0.359375, val_acc 0.391000, time 4\n",
      "iteration 400 / 15000: loss 1.841293\n",
      "iteration 500 / 15000: loss 1.534809\n",
      "iteration 600 / 15000: loss 1.483581\n",
      "iteration 700 / 15000: loss 1.336817\n",
      "train_acc 0.531250, val_acc 0.491000, time 9\n",
      "iteration 800 / 15000: loss 1.461629\n",
      "iteration 900 / 15000: loss 1.508736\n",
      "iteration 1000 / 15000: loss 1.163824\n",
      "iteration 1100 / 15000: loss 1.354160\n",
      "train_acc 0.570312, val_acc 0.545000, time 14\n",
      "iteration 1200 / 15000: loss 1.259659\n",
      "iteration 1300 / 15000: loss 1.479382\n",
      "iteration 1400 / 15000: loss 1.186748\n",
      "iteration 1500 / 15000: loss 1.349476\n",
      "train_acc 0.468750, val_acc 0.561000, time 20\n",
      "iteration 1600 / 15000: loss 1.422179\n",
      "iteration 1700 / 15000: loss 1.201795\n",
      "iteration 1800 / 15000: loss 1.474555\n",
      "iteration 1900 / 15000: loss 1.094366\n",
      "train_acc 0.476562, val_acc 0.573000, time 23\n",
      "iteration 2000 / 15000: loss 1.233943\n",
      "iteration 2100 / 15000: loss 1.210773\n",
      "iteration 2200 / 15000: loss 1.117206\n",
      "train_acc 0.562500, val_acc 0.594000, time 27\n",
      "iteration 2300 / 15000: loss 1.381386\n",
      "iteration 2400 / 15000: loss 1.166435\n",
      "iteration 2500 / 15000: loss 1.156002\n",
      "iteration 2600 / 15000: loss 1.051123\n",
      "train_acc 0.601562, val_acc 0.599000, time 30\n",
      "iteration 2700 / 15000: loss 1.233492\n",
      "iteration 2800 / 15000: loss 1.078157\n",
      "iteration 2900 / 15000: loss 1.136730\n",
      "iteration 3000 / 15000: loss 0.986995\n",
      "train_acc 0.617188, val_acc 0.604000, time 34\n",
      "iteration 3100 / 15000: loss 1.132000\n",
      "iteration 3200 / 15000: loss 1.138462\n",
      "iteration 3300 / 15000: loss 1.182975\n",
      "iteration 3400 / 15000: loss 1.178325\n",
      "train_acc 0.640625, val_acc 0.604000, time 37\n",
      "iteration 3500 / 15000: loss 1.194806\n",
      "iteration 3600 / 15000: loss 1.191540\n",
      "iteration 3700 / 15000: loss 1.143066\n",
      "iteration 3800 / 15000: loss 1.230856\n",
      "train_acc 0.609375, val_acc 0.613000, time 40\n",
      "iteration 3900 / 15000: loss 1.158274\n",
      "iteration 4000 / 15000: loss 1.060990\n",
      "iteration 4100 / 15000: loss 1.151808\n",
      "iteration 4200 / 15000: loss 1.159805\n",
      "train_acc 0.718750, val_acc 0.606000, time 44\n",
      "iteration 4300 / 15000: loss 1.228290\n",
      "iteration 4400 / 15000: loss 1.125951\n",
      "iteration 4500 / 15000: loss 1.023641\n",
      "train_acc 0.664062, val_acc 0.624000, time 47\n",
      "iteration 4600 / 15000: loss 1.229601\n",
      "iteration 4700 / 15000: loss 1.065055\n",
      "iteration 4800 / 15000: loss 1.016254\n",
      "iteration 4900 / 15000: loss 1.023399\n",
      "train_acc 0.710938, val_acc 0.632000, time 50\n",
      "iteration 5000 / 15000: loss 1.149799\n",
      "iteration 5100 / 15000: loss 1.116200\n",
      "iteration 5200 / 15000: loss 1.124071\n",
      "iteration 5300 / 15000: loss 1.089613\n",
      "train_acc 0.562500, val_acc 0.637000, time 54\n",
      "iteration 5400 / 15000: loss 0.974313\n",
      "iteration 5500 / 15000: loss 1.126423\n",
      "iteration 5600 / 15000: loss 1.154233\n",
      "iteration 5700 / 15000: loss 1.088650\n",
      "train_acc 0.593750, val_acc 0.643000, time 57\n",
      "iteration 5800 / 15000: loss 1.028226\n",
      "iteration 5900 / 15000: loss 1.158712\n",
      "iteration 6000 / 15000: loss 1.026530\n",
      "iteration 6100 / 15000: loss 1.056348\n",
      "train_acc 0.625000, val_acc 0.646000, time 60\n",
      "iteration 6200 / 15000: loss 1.057159\n",
      "iteration 6300 / 15000: loss 0.974386\n",
      "iteration 6400 / 15000: loss 0.937835\n",
      "train_acc 0.750000, val_acc 0.650000, time 64\n",
      "iteration 6500 / 15000: loss 0.943476\n",
      "iteration 6600 / 15000: loss 1.136730\n",
      "iteration 6700 / 15000: loss 1.040972\n",
      "iteration 6800 / 15000: loss 1.058443\n",
      "train_acc 0.664062, val_acc 0.655000, time 67\n",
      "iteration 6900 / 15000: loss 0.868746\n",
      "iteration 7000 / 15000: loss 0.822824\n",
      "iteration 7100 / 15000: loss 1.137407\n",
      "iteration 7200 / 15000: loss 0.885385\n",
      "train_acc 0.687500, val_acc 0.647000, time 70\n",
      "iteration 7300 / 15000: loss 0.880590\n",
      "iteration 7400 / 15000: loss 1.039905\n",
      "iteration 7500 / 15000: loss 1.011912\n",
      "iteration 7600 / 15000: loss 1.127931\n",
      "train_acc 0.695312, val_acc 0.673000, time 74\n",
      "iteration 7700 / 15000: loss 1.022487\n",
      "iteration 7800 / 15000: loss 1.047794\n",
      "iteration 7900 / 15000: loss 1.017711\n",
      "iteration 8000 / 15000: loss 0.969428\n",
      "train_acc 0.726562, val_acc 0.671000, time 77\n",
      "iteration 8100 / 15000: loss 0.999691\n",
      "iteration 8200 / 15000: loss 1.033162\n",
      "iteration 8300 / 15000: loss 1.023800\n",
      "iteration 8400 / 15000: loss 0.962012\n",
      "train_acc 0.593750, val_acc 0.674000, time 81\n",
      "iteration 8500 / 15000: loss 0.875089\n",
      "iteration 8600 / 15000: loss 0.824931\n",
      "iteration 8700 / 15000: loss 0.927520\n",
      "train_acc 0.726562, val_acc 0.669000, time 84\n",
      "iteration 8800 / 15000: loss 0.914531\n",
      "iteration 8900 / 15000: loss 0.849600\n",
      "iteration 9000 / 15000: loss 0.850175\n",
      "iteration 9100 / 15000: loss 0.992343\n",
      "train_acc 0.640625, val_acc 0.664000, time 88\n",
      "iteration 9200 / 15000: loss 0.974157\n",
      "iteration 9300 / 15000: loss 0.850525\n",
      "iteration 9400 / 15000: loss 0.822269\n",
      "iteration 9500 / 15000: loss 1.057659\n",
      "train_acc 0.718750, val_acc 0.653000, time 91\n",
      "iteration 9600 / 15000: loss 0.997555\n",
      "iteration 9700 / 15000: loss 1.008870\n",
      "iteration 9800 / 15000: loss 1.057199\n",
      "iteration 9900 / 15000: loss 1.077628\n",
      "train_acc 0.687500, val_acc 0.680000, time 94\n",
      "iteration 10000 / 15000: loss 0.992972\n",
      "iteration 10100 / 15000: loss 0.887109\n",
      "iteration 10200 / 15000: loss 0.781769\n",
      "iteration 10300 / 15000: loss 0.947490\n",
      "train_acc 0.726562, val_acc 0.668000, time 98\n",
      "iteration 10400 / 15000: loss 0.908332\n",
      "iteration 10500 / 15000: loss 0.923751\n",
      "iteration 10600 / 15000: loss 0.796561\n",
      "train_acc 0.710938, val_acc 0.680000, time 101\n",
      "iteration 10700 / 15000: loss 0.826473\n",
      "iteration 10800 / 15000: loss 0.879193\n",
      "iteration 10900 / 15000: loss 0.889710\n",
      "iteration 11000 / 15000: loss 0.848626\n",
      "train_acc 0.687500, val_acc 0.679000, time 105\n",
      "iteration 11100 / 15000: loss 0.903926\n",
      "iteration 11200 / 15000: loss 1.138004\n",
      "iteration 11300 / 15000: loss 0.876676\n",
      "iteration 11400 / 15000: loss 0.909138\n",
      "train_acc 0.679688, val_acc 0.673000, time 108\n",
      "iteration 11500 / 15000: loss 0.895081\n",
      "iteration 11600 / 15000: loss 0.861597\n",
      "iteration 11700 / 15000: loss 1.157845\n",
      "iteration 11800 / 15000: loss 0.990209\n",
      "train_acc 0.656250, val_acc 0.695000, time 112\n",
      "iteration 11900 / 15000: loss 0.893353\n",
      "iteration 12000 / 15000: loss 0.750755\n",
      "iteration 12100 / 15000: loss 0.827303\n",
      "iteration 12200 / 15000: loss 0.954702\n",
      "train_acc 0.710938, val_acc 0.695000, time 115\n",
      "iteration 12300 / 15000: loss 0.831285\n",
      "iteration 12400 / 15000: loss 0.900263\n",
      "iteration 12500 / 15000: loss 0.804226\n",
      "iteration 12600 / 15000: loss 0.995109\n",
      "train_acc 0.718750, val_acc 0.698000, time 119\n",
      "iteration 12700 / 15000: loss 0.856005\n",
      "iteration 12800 / 15000: loss 0.834081\n",
      "iteration 12900 / 15000: loss 0.887052\n",
      "train_acc 0.750000, val_acc 0.678000, time 122\n",
      "iteration 13000 / 15000: loss 0.940602\n",
      "iteration 13100 / 15000: loss 0.922677\n",
      "iteration 13200 / 15000: loss 0.996318\n",
      "iteration 13300 / 15000: loss 0.790748\n",
      "train_acc 0.726562, val_acc 0.691000, time 125\n",
      "iteration 13400 / 15000: loss 1.040650\n",
      "iteration 13500 / 15000: loss 0.924309\n",
      "iteration 13600 / 15000: loss 0.983422\n",
      "iteration 13700 / 15000: loss 0.738111\n",
      "train_acc 0.687500, val_acc 0.702000, time 129\n",
      "iteration 13800 / 15000: loss 0.766118\n",
      "iteration 13900 / 15000: loss 0.878795\n",
      "iteration 14000 / 15000: loss 0.852108\n",
      "iteration 14100 / 15000: loss 0.850525\n",
      "train_acc 0.726562, val_acc 0.697000, time 132\n",
      "iteration 14200 / 15000: loss 0.802646\n",
      "iteration 14300 / 15000: loss 0.937250\n",
      "iteration 14400 / 15000: loss 0.786440\n",
      "iteration 14500 / 15000: loss 0.795184\n",
      "train_acc 0.742188, val_acc 0.700000, time 136\n",
      "iteration 14600 / 15000: loss 0.901027\n",
      "iteration 14700 / 15000: loss 0.893916\n",
      "iteration 14800 / 15000: loss 1.122639\n",
      "train_acc 0.679688, val_acc 0.696000, time 139\n",
      "iteration 14900 / 15000: loss 0.712603\n",
      "iteration 15000 / 15000: loss 0.883354\n",
      "Train accuracy:  0.727959183673\n",
      "Validation accuracy:  0.704\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hidden_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d5a9c0585c5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"feats.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtune\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate_decay\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtune\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hidden_size' is not defined"
     ]
    }
   ],
   "source": [
    "f=open(\"feats.csv\",\"a\")\n",
    "tune=[hidden_size,momentum,dropout,learning_rate,learning_rate_decay]\n",
    "f.write(str(tune+[train_acc,val_acc]).strip(\"[]\")+'\\n')\n",
    "f.close()\n",
    "with open(\"feats/\"+ str([val_acc]+tune).strip(\"[]\")+'.pickle','w') as f:\n",
    "    pickle.dump(stats,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fcda00b2890>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the loss function and train / validation accuracies\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "#plt.savefig(\"dropout loss_history.eps\")\n",
    "\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "plt.ylabel('Clasification accuracy')\n",
    "#plt.savefig('dropout accuracy.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size=1000\n",
    "momentum=.9\n",
    "learning_rate=1e-3\n",
    "learning_rate_decay=.99\n",
    "reg=.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
